---
title: "STAT/MATH 495: Problem Set 07"
author: "MERON GEDRAGO"
date: "2017-10-24"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)
library(pROC)
library(ROCR)

train <- read_csv("data/cs-training.csv") %>% 
  rename(Id = X1) %>%  na.omit()
test <- read_csv("data/cs-test.csv") %>% 
  rename(Id = X1) %>%  na.omit()
submission <- read_csv("data/sampleEntry.csv")
 
```

Information on the competition can be found [here](https://www.kaggle.com/c/GiveMeSomeCredit/data).



# Collaboration

Please indicate who you collaborated with on this assignment: 



# Build binary classifier

Build the binary classifier based on a single predictor variable: `DebtRatio`,
`age`, or `MonthlyIncome`. Justify this choice.

```{r, include=FALSE, eval= FALSE}
cor(train)

```
I decided to look at the correlation matrix to decide which variable to take as a predictor variable. The correlation of DebtRatio`,
`age`, or `MonthlyIncome` with 'SeriousDlqin2yrs' is as follows -0.003291309,-0.102684838 and -0.019745547 respectively. As we can see, 'age' is the most correlated with 'SeriousDlqin2yrs' out of the three so we choose 'age' to be our predictor variable. 


# ROC curve

Based on the ultimate classifier you choose, plot a corresponding ROC curve.

```{r,include=FALSE, eval= FALSE}
#plot(roc(train$SeriousDlqin2yrs ~ train$age, train, smooth=TRUE))
```

```{r,include=FALSE }
#creating a logit function 
model_formula <- as.formula(train$SeriousDlqin2yrs~train$age)
model_logistic <- glm(model_formula, data=train, family="binomial")
 
#cleaning up 
model_logistic %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  sample_n(5)

#finding the fitted values for the train dataset
train_augmented <- model_logistic %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted)))

```


The ROC plot below shows that the accuracy of age as a predictor in our model. We can see the arch of the curve and also use the area of the curve of 0.635 to determine how well age is doing. In this case, age seems to be a poor to fair in accuracy.  
```{r,include= FALSE}

# This bit of code computes the ROC curve
pred <- prediction(predictions = train_augmented$p_hat, labels =  train_augmented$train.SeriousDlqin2yrs)
perf <- performance(pred, "tpr","fpr")

# This bit of code computes the Area Under the Curve
auc <- as.numeric(performance(pred,"auc")@y.values)
auc

```

```{r}
#plotting the ROC curve 
plot(perf, main=paste("Area Under the Curve =", round(auc, 3)))
abline(c(0, 1), lty=2)
```

```{r,include= FALSE}
#predict outcomes for test data 
log_odds_hat <- predict(model_logistic, newdata= test)
p_hat <- 1/(1 + exp(-log_odds_hat))

```



# ROC curve for random guessing

Instead of using any predictor information as you did above, switch your
predictions to random guesses and plot the resulting ROC curve.

The below ROC curve shows a straight diagonal line across the specificity vs the sensitivity of the graph. This means that the area under the curve is 0.5 and the model is useless to us.  
```{r, include=FALSE }
set.seed(40)
randomP_hats <- sample(c(0,1), 120269 , replace = TRUE)

pred <- prediction(predictions = randomP_hats , labels =  train_augmented$train.SeriousDlqin2yrs)
perf <- performance(pred, "tpr","fpr")

```


```{r}
#plotting the ROC curve 
plot(perf, main=paste("ROC curve with random values"))
abline(c(0, 1), lty=2)

```
